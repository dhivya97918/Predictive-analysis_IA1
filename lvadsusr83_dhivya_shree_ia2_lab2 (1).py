# -*- coding: utf-8 -*-
"""LVADSUSR83_Dhivya_Shree_IA2_Lab2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EKVgZG7urX_-H2jg7gdD28CxtJi-UaRb
"""

#2
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_score

data = pd.read_csv("/content/sample_data/Mall_Customers.csv")
#1 Data Preprocessing-normalization
X=data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# Drop any rows with missing values
data.dropna(inplace=True)
data['ratio'] = data['Spending Score (1-100)'] / data['Annual Income (k$)']
#2 Elbow method
sse = []
k_rng = range(1,10)
for k in k_rng:
    km = KMeans(n_clusters=k)
    km.fit(data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)','ratio']])
    sse.append(km.inertia_)
# Features
X = data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)','ratio']]
#3 kmeans- Model
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_scaled)
data['Cluster'] = kmeans.labels_
#silhoutte_avg
silhouette_avg = silhouette_score(X_scaled, kmeans.labels_)
print("Silhouette Score:", silhouette_avg)
#4 Visualize the clusters
plt.figure(figsize=(10, 6))
plt.scatter(data['Annual Income (k$)'], data['Spending Score (1-100)'], c=data['Cluster'], cmap='viridis')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title('Customer Segmentation')
plt.show()
for i in range(3):
    cluster_data = data[data['Cluster'] == i]
    print(f"Cluster {i+1}:")
    print(cluster_data.describe())